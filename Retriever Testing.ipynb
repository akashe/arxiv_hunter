{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'farm-haystack[all]'\n",
    "!pip install pytorch-lightning==1.7.7\n",
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d9e5833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_all_files_with_extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655826cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.utils import launch_milvus()\n",
    "launch_milvus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "742d21fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/espnet2/gan_tts/vits/vits.py:43: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(torch.__version__) >= LooseVersion(\"1.6.0\"):\n"
     ]
    }
   ],
   "source": [
    "from haystack.document_stores import MilvusDocumentStore\n",
    "#document_store = FAISSDocumentStore(sql_url=\"sqlite:///data/my_doc_store.db\",faiss_index_factory_str=\"Flat\",similarity=\"dot_product\", embedding_dim=128)\n",
    "\n",
    "document_store = MilvusDocumentStore(sql_url=\"sqlite:///data/my_doc_store.db\",similarity=\"dot_product\", embedding_dim=128, progress_bar= True)\n",
    "\n",
    "json_locations = \"data/extract_json\"\n",
    "\n",
    "all_json_files = get_all_files_with_extension(json_locations, \"json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ffd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "documents = []\n",
    "for i in all_json_files:\n",
    "    with open(i,\"r\") as f:\n",
    "        document = json.load(f)\n",
    "    \n",
    "    for j in document[\"paras\"]:\n",
    "        dict_ = {\n",
    "            'content' : j,\n",
    "            'meta': {\n",
    "                'file_name' : document['file_name'],\n",
    "                'abstract' : document['abstract'],\n",
    "                'authors' : document['authors'] if 'authors' in document else None,\n",
    "                'title': document['title']  if 'title' in document else None\n",
    "                \n",
    "            }\n",
    "        }\n",
    "        documents.append(dict_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b62935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6e21bed81545d3bab801d79715d90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/996193 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.write_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54891f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "checkpoint = torch.load(\"trained_model/epoch=0-step=49049.ckpt\",map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b08cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Retriever(\n",
       "  (query_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (passage_encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc_query): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (fc_passage): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (layer_norm_query): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (layer_norm_passage): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import Retriever\n",
    "from train_sagemaker import TrainConfig\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "config = TrainConfig()\n",
    "model = Retriever(config).to(device)\n",
    "\n",
    "\n",
    "if device.type == 'cpu':\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"],map_location=torch.device('cpu'))\n",
    "else:\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    \n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dfb73c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.nodes import DensePassageRetriever\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "Building a custom retriever because the implementation in haystack wants the passage and query encode to be disjoint \n",
    "models with their tokenizers beings accessile with the huggingface path or local path\n",
    "\n",
    "Referred from : https://github.com/deepset-ai/haystack/blob/main/haystack/nodes/retriever/dense.py\n",
    "\n",
    "Missing functionalities:\n",
    "    1. using filters for metadata\n",
    "    2. batch retrieve\n",
    "'''\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, text):\n",
    "        self.data = text\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "\n",
    "def collate_fn(passages, tokenizer, passage_max_len):\n",
    "    tokenized_passages = tokenizer(passages, padding= True, truncation= True, max_length=passage_max_len, return_tensors=\"pt\")\n",
    "    \n",
    "    return tokenized_passages\n",
    "    \n",
    "\n",
    "class CustomDensePassageRetriever():\n",
    "    def __init__(\n",
    "        self,\n",
    "        document_store,\n",
    "        model,\n",
    "        query_tokenizer_loc,\n",
    "        passage_tokenizer_loc,\n",
    "        max_seq_len_query: int = 64,\n",
    "        max_seq_len_passage: int = 288,\n",
    "        top_k: int = 10,\n",
    "        use_gpu: bool = True,\n",
    "        batch_size: int = 16,\n",
    "        scale_score: bool = True,\n",
    "    ):\n",
    "        self.document_store = document_store\n",
    "        self.model = model\n",
    "        self.query_tokenizer = AutoTokenizer.from_pretrained(query_tokenizer_loc)\n",
    "        self.passage_tokenizer = AutoTokenizer.from_pretrained(passage_tokenizer_loc)\n",
    "        \n",
    "        self.max_seq_len_query = max_seq_len_query\n",
    "        self.max_seq_len_passage = max_seq_len_passage\n",
    "        self.topk = top_k\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.scale_score = scale_score\n",
    "        \n",
    "    def embed_documents(self, documents):\n",
    "       \n",
    "        \"\"\"\n",
    "        # possible speed up by using Dataloaders??\n",
    "        text = [i[\"content\"] for i in documents]\n",
    "        \n",
    "        dataset = CustomDataset(text)\n",
    "        collate_fn = partial(collate_fn, self.passage_tokenizer, self.max_seq_len_passage)\n",
    "        \n",
    "        datalaoder = DataLoader(dataset, batch_size= self.batch_size, collate_fn=collate_fn_)\n",
    "        \"\"\"\n",
    "        \n",
    "        document_embeddings = []\n",
    "        \n",
    "        with tqdm(range(len(documents)), desc= \"Creating document embeddings\", unit=\"Docs\") as progress_bar:\n",
    "            for i in range(0, len(documents), self.batch_size):\n",
    "                text_ = documents[i:i+self.batch_size]\n",
    "                \n",
    "                text = [i.content for i in text_]\n",
    "\n",
    "                tokenized_passages = self.passage_tokenizer(text, padding= True, truncation= True, \\\n",
    "                                                            max_length=self.max_seq_len_passage, return_tensors=\"pt\").to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    encoded_passage = self.model.passage_encoder(**tokenized_passages)\n",
    "                    encoded_passage_representation = encoded_passage.pooler_output\n",
    "\n",
    "                    if self.model.config.projection:\n",
    "                        encoded_passage_representation = self.model.fc_passage(encoded_passage_representation)\n",
    "\n",
    "                    encoded_passage_representation = self.model.layer_norm_passage(encoded_passage_representation)\n",
    "\n",
    "                document_embeddings.append(encoded_passage_representation.cpu().numpy())\n",
    "                progress_bar.update(self.batch_size)\n",
    "        \n",
    "        return np.concatenate(document_embeddings, axis=0)\n",
    "        \n",
    "        \n",
    "\n",
    "    def embed_queries(self, queries):\n",
    "        \n",
    "        \n",
    "        query_embeddings = []\n",
    "        for i in range(0, len(queries), self.batch_size):\n",
    "            text = queries[i:i+self.batch_size]\n",
    "            \n",
    "            tokenized_queries = self.query_tokenizer(text, padding= True, truncation= True,\n",
    "                                                     max_length=self.max_seq_len_query, return_tensors=\"pt\").to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                encoded_query = self.model.query_encoder(**tokenized_queries)\n",
    "                encoded_query_representation = encoded_query.pooler_output\n",
    "\n",
    "                if self.model.config.projection:\n",
    "                    encoded_query_representation = self.model.fc_query(encoded_query_representation)\n",
    "\n",
    "                encoded_query_representation = self.model.layer_norm_query(encoded_query_representation)\n",
    "\n",
    "                query_embeddings.append(encoded_query_representation.cpu().numpy())\n",
    "                \n",
    "        return np.concatenate(query_embeddings, axis=0)\n",
    "        \n",
    "\n",
    "    def retrieve(self,query,\n",
    "                    top_k = None,\n",
    "                    index = None,\n",
    "                    headers = None,\n",
    "                    scale_score = None,\n",
    "                    document_store = None,\n",
    "                     filters = None\n",
    "                    ):\n",
    "\n",
    "            document_store = document_store or self.document_store\n",
    "\n",
    "            assert document_store != None\n",
    "\n",
    "            if top_k is None:\n",
    "                top_k = self.topk\n",
    "\n",
    "            if index is None:\n",
    "                index = document_store.index\n",
    "\n",
    "            if scale_score is None:\n",
    "                scale_score = self.scale_score\n",
    "\n",
    "            query_emb = self.embed_queries(queries=[query])\n",
    "\n",
    "            documents = document_store.query_by_embedding(\n",
    "                    query_emb=query_emb[0], top_k=top_k, filters=filters, index=index, headers=headers, scale_score=scale_score\n",
    "                )\n",
    "\n",
    "            return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0316b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = CustomDensePassageRetriever(document_store=document_store,\n",
    "                                        model=model,\n",
    "                                        query_tokenizer_loc='bert-base-uncased',\n",
    "                                        passage_tokenizer_loc='bert-base-uncased',\n",
    "                                        top_k = 5,\n",
    "                                        batch_size = 768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c168e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df3d097966d498c97f796de97325bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Updating Embedding:   0%|          | 0/994444 [00:00<?, ? docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae0dd0f8d5e4d2f9a13b71b092a28c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5950abd8599f476881a1d118ebf0e4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d6efb8fa2442b0bf33d206c5985fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3cc53312ae49d3b027f63d51e17a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37951cf7db7042b2ab70a8f81aa65ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a7b64437a7641a1892fb41cddf0b21b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "541c507ef5c948e49e12169c16205a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4ed4ebb01c4b2a9753d286ff0c1df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4048ce10ddf4842a36ddb29b779402a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fb73a0322f4675a343c741ee66394f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf24a9695d3444b96df5ba0738155f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa016cedd024fe49d02d7c49039d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597351e2b4e54c95a9fafb0fa7c822c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f8589b53054a5e8d4bdf299131d73c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1c52d7d63e4bb4bbfff37f1c503ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51ccc96ff814ee796e7f2121e6c096a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e71b1fb10bc4d61a0ac0455d1746516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f1fd8996f5475c825269558d5b51c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325df0b4d2c1475a98276b40b20b17ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29feed100ea440da880320072d4bcddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5cb531f7d2e4f3c82cfadec58404e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e057f824d3634572a1c94851c6bb9267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad234eef41e49d399ee4523d9ecbca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f4adf1fc3134b5eadadf4334d882faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36786931d6e4a999e1b08e39a80ab60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f0415dea834cbe99935b1c701a73fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3b4df3df394962a61ce159080d2208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ef0a187b8f4b9ab7ab62778c8292e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21af45388a904993894970c040860f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "448d669ba12245d29b0055386d318621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe7d1c7ee1c4d0d9f0e6db49dae0e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ec85af858474d16a3c16df16e1e476c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0376142fc1b4adf912850657a77881d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234667c6af1448299484a79877f2ead6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dded8117137481bb336c29f7a78f2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f6dc5ef02449feb9d75d796d29f477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "881d200b2a314f86820f3690338880a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636ce1d183e54750b9c56c4c8c79b3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20525c389a874bc698ca0e1fb57de935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3eeee084906459f865cb013c4202936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7a042e2bfe4934abc1445ccaf2e54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bd91b965004000b6767993eb776d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating document embeddings:   0%|          | 0/10000 [00:00<?, ?Docs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c396abf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store.save(index_path=\"/home/ec2-user/SageMaker/arxiv_hunter/data/saved_store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8561c808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sketch-Based Anomaly Detection in Streaming Graphs\n",
      "2106.04486v2.pdf.txt\n",
      "This ensures that the current submatrix is as condensed as possible (line 9). As defined in Definition 2, AnoEdge-L computes the likelihood score of the edge with respect to (,) (line 10). A higher likelihood measure implies that the edge is more likely to be anomalous. Algorithm 3: AnoEdge-L : Streaming Anomaly Edge Scor- ing Input: Stream  of edges over time Output: Anomaly score per edge 1 Procedure AN OEDGE-L() /* H-CMS data structure */ 2 Initialize H-CMS matrix M for edges count /* mutable submatrix */ 3 Initialize a randomly picked 1  1 submatrix (,) 4 while new edge  = (, ,,)   is received do /* decay count */ 5 Temporal decay H-CMS with timestamp change 6 Update H-CMS matrix M for new edge (, ) with value  // update count 7  Check and Update Submatrix: 8 Expand (,) // expand submatrix 9 Condense (,) // condense submatrix /* likelihood score from Definition 2 */ 10 output ()  L(M,(),(),,)\n",
      "Quiver neural networks\n",
      "2207.12773v1.pdf.txt\n",
      "Specifically, if the original widths are given by the dimension vector d, then the compressed widths are given by the reduced dimension vector dred. The algorithm proceeds by computing successive QR decompositions according to a topological order of the vertices. The resulting upper-triangular matrix leads to the reduced weights, while 8 IORDAN GANEV AND ROBIN WALTERS Algorithm 1: QR Model Compression for Rescaling activations (QR-Compress) input : Q-neural network (d, W, ) with each i rescaling output : Q-neural network (dred, Wred, ), orthogonal matrices Q = (Qi  O(di))iIhidden Q, Wred,   [ ], [ ], [ ] // initialize output matrix lists I = top_sort(I) // topological order of vertices for i in I do Mi  hstack  WeQs(e)Incs(e) : t(e) = i  // merge transf. incoming weights if i is not a source or a sink then Qi, Ri  QR-decomp(Mi, mode = complete) // Mi = QiInciRi i  i  Q1 i  i  Qi \n",
      "Revisiting Crowd Counting: State-of-the-art, Trends, and Future\n",
      "  Perspectives\n",
      "2209.07271v1.pdf.txt\n",
      "[71] - - - composite (l2 + cross-entropy) loss MSE, MAE PCCNet [69] patches 512  680 - l2 loss MSE, MAE SASNet [77] patch 128  128 - composite (l2 + lSSIM) loss MSE, MAE M-SFANet [79] image arbitrary image size/2 BL (lBayes) RMSE, MAE, GAME M-SegNet [79] image arbitrary image size/2 BL (lBayes) RMSE, MAE, GAME SGANet [23] patch 128  128 input size/4 curriculum loss RMSE, MAE FusionCount [60] patch 384  512 - l2 loss RMSE, MAE MAN [101] patch 512  512 - composite loss MSE, MAE MFCC [78] image 512  640 input size l2 loss RMSE, MAE TAFNet [72] image arbitrary - l2 loss RMSE, GAME TransCrowd [96] image 1152  768 - l1 loss MSE, MAE 4) Patch Mean Absolute Error (PMAE): PMAE = 1 m  N mN  i=1 |Cpred Ii  Cgt Ii | (15) where m is the number of non-overlapping patches in each image. When m = 1, PMAE become equivalent to MAE.\n",
      "Understanding Dataset Difficulty with $\\mathcal{V}$-Usable Information\n",
      "2110.08420v2.pdf.txt\n",
      "different instances (x, y) by computing PVI (x  y) for the same X, Y, V (Tables 1, 4; Fig. 11) v. different slices or subsets of the data by computing the average PVI over instances in each slice (Table 2; Fig. 5). Understanding Dataset Difficulty with V-Usable Information Algorithm 1 After finetuning on a dataset of size n, the V-information and PVI can be calculated in O(n) time. Input: training data Dtrain = {(input xi, gold label yi)}m i=1, held- out data Dtest = {(input xi, gold label yi)}n i=1, model V do g  Finetune V on Dtrain   empty string (null input) g  Finetune V on {(, yi) | (xi, yi)  Dtrain} HV(Y ), HV(Y |X)  0, 0 for (xi, yi)  Dtest do HV(Y )  HV(Y )\n",
      "An Online Sparse Streaming Feature Selection Algorithm\n",
      "2208.01562v2.pdf.txt\n",
      "Kj is the known entry set of Ft 13 update pm, qj according to (1) 14 end for 15 end for 16 iter = iter+1 17 end while 18 B =PQT 19 /*online relevance analysis*/ 20 for i = t to t+Bs-1 21 fetch F j from B 22 If re-Dep(C, F j |) 23 /*online redundancy analysis I*/ 24 If S  SF s.t. re - Ind(C, F j | S) 25 discard F j and continue 26 end if 27 SF = SFF j 28 /*online redundancy analysis II*/ 29 for each feature Q  SF- F j 30 if S  SF-Q s.t. re-Ind(C, Q|S) 31 SF = SF - Q 32 end if 33 end for 34 else if not re-Ind(C, F j |) 35 /*online fuzzy correlation analysis */ 36 FSF = FSFF j 37 Calculated F j (C) by (7) and sorted in FSF 38 end if 39 end for 40 Add the top |SF|/2 of FSF to SF 41 B=, t=t+1 42 Until no features are available Output selected completed streaming features subset SF Online relevance analysis\n"
     ]
    }
   ],
   "source": [
    "for doc in retriever.retrieve(\"Attention NLP decoder\"):\n",
    "    print(doc.meta[\"title\"])\n",
    "    print(doc.meta['file_name'])\n",
    "    print(doc.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
